import numpy as np
from matplotlib import pyplot as plt
import math
import cv2
import pymap3d

image_front = image_back = image_left = image_right = None
point_cloud = []

front_projection= np.zeros((2048,2048), dtype = float)
back_projection = np.zeros((2048,2048), dtype = float)
left_projection = np.zeros((2048,2048), dtype = float)
right_projection = np.zeros((2048,2048), dtype = float)

# Lat, Lon, Alt, Qs, Qx, Qy, Qz
camera_config = []
with open("data/image/camera.config", "r") as config:
    config.readline()
    secondline = config.readline()
    config = secondline.split(", ")
    for i in range(0, len(config)):
        config[i]=float(config[i])
    camera_config.append(float(config[i]))
camera_config=config
print(camera_config)
def read_image_files():
    
    image_front = cv2.imread("data/image/front.jpg", cv2.IMREAD_COLOR)
    image_back = cv2.imread("data/image/back.jpg", cv2.IMREAD_COLOR)
    image_left = cv2.imread("data/image/left.jpg", cv2.IMREAD_COLOR)
    image_right = cv2.imread("data/image/right.jpg", cv2.IMREAD_COLOR)
   
    
    with open("data/final_project_point_cloud.fuse") as csv:
        for line in csv:
            point_array = line.split(" ")
            for i in range(0, len(point_array)):
                point_array[i] = float(point_array[i])
            point_cloud.append(point_array)

    return point_cloud

def enu_to_camera_coords(east, north, up,camera_config):
    
    qs = camera_config[3]
    
    qx = camera_config[4]
    qy = camera_config[5]
    qz = camera_config[6]
    row_1_col_1 = (qs * qs) + (qx * qx) - (qy * qy) - (qz * qz)
    row_1_col_2 = (2 * qx * qy) - (2 * qs * qz)
    row_1_col_3 = (2 * qx * qz) + (2 * qs * qy)
    row_2_col_1 = (2 * qx * qy) + (2 * qs * qz)
    row_2_col_2 = (qs * qs) - (qx * qx) + (qy * qy) - (qz * qz)
    row_2_col_3 = (2 * qz * qy) - (2 * qs * qx)
    row_3_col_1 = (2 * qx * qz) - (2 * qs * qy)
    row_3_col_2 = (2 * qz * qy) + (2 * qs * qx)
    row_3_col_3 = (qs * qs) - (qx * qx) - (qy * qy) + (qz * qz)
    rq = [[row_1_col_1, row_1_col_2, row_1_col_3], [row_2_col_1, row_2_col_2, row_2_col_3], [row_3_col_1, row_3_col_2, row_3_col_3]]
    camera_coordinates = np.dot(rq, [north, east, -up])
    x = camera_coordinates[0]
    y = camera_coordinates[1]
    z = camera_coordinates[2]
    return x, y, z

def convert_point(point):
       # Convert point geodetic coordinates (lat, lon, alt) to ECEF coordinates (x, y, z)
    x_ecef, y_ecef, z_ecef = pymap3d.geodetic2ecef(point[0], point[1], point[2])
    
    # Convert point ECEF coordinates (x, y, z) to ENU coordinates (East, North, Up)
    # pymap3d.ecef2enu(point[0], point[1], point[2], lat0, lon0, h0) where 0 is camera coordinates
    u_east, v_north, w_up = pymap3d.ecef2enu(x_ecef, y_ecef, z_ecef, camera_config[0], camera_config[1], camera_config[2])

    # Convert ENU coordinates to camera perspective
##    camera_x, camera_y, camera_z=pymap3d.geodetic2enu(point[0],point[1],point[2],camera_config[0], camera_config[1], camera_config[2])
    camera_x, camera_y, camera_z = enu_to_camera_coords(u_east, v_north, w_up,camera_config)
    
    return camera_x, camera_y, camera_z

def write_to_image_file(write_file, a, b, c):
    xi = int( ((a / c) * 1024) + 1024)
    yi = int( ((b / c) * 1024) + 1024)
    
    xi= xi%2048
    yi= yi%2048
    write_file[xi][yi] = 255

def map_points(point_cloud):
    car_x,car_y,car_z=convert_point(camera_config)

    for point in point_cloud:
##        car_x=camera_config[0]
##        print(car_x)
##        car_y=camera_config[1]
##        print(car_y)
##        car_z=camera_config[2]
##        print(car_z)
##        car_x,car_y,car_z=convert_point(camera_config,camera_config)

        camera_x, camera_y, camera_z = convert_point(point)
##        print(car_x,car_y,car_z)

##        print(camera_x,camera_y,camera_z)
##        camera_x=(abs(camera_x)-abs(car_x))
##        print(camera_x)
##        camera_y=(abs(camera_y)-abs(car_y))
##        print(camera_y)

##        camera_z=(abs(camera_z)-abs(car_z)
        z_is_positive = ((camera_z) > 0)
        y_is_positive= ((camera_y) > 0)
        x_is_positive = ((camera_x) > 0)

#left
        z_from_camera_more_than_x_from_camera = (abs(camera_z) > abs(camera_x))
        z_from_camera_more_than_y_from_camera = (abs(camera_z) > abs(camera_y))
#right        
        z_more_than_x_from_camera = (camera_z > abs(camera_x))
        z_more_than_y_from_camera = (camera_z > abs(camera_y))

#front  
        x_from_camera_more_than_z_from_camera = (abs(camera_y) > abs(camera_z))
        x_from_camera_more_than_y_from_camera = (abs(camera_y) > abs(camera_x))
        
        x_more_than_y_from_camera = (camera_y > abs(camera_x))
        x_more_than_z_from_camera = (camera_y > abs(camera_z))
        
        
        
        neg_x=-camera_x
        neg_z=-camera_z
        neg_y=-camera_y

        #actual right
        if z_is_positive and z_more_than_x_from_camera and z_more_than_y_from_camera:
            write_to_image_file(right_projection, camera_x, camera_y, camera_z)
        #actual left
        if (not z_is_positive) and (z_from_camera_more_than_x_from_camera) and z_from_camera_more_than_y_from_camera:
            write_to_image_file(left_projection, camera_x, camera_y, neg_z)
        
        if (y_is_positive) and x_more_than_z_from_camera and x_more_than_y_from_camera:
            write_to_image_file(front_projection, camera_x, camera_z, camera_y)

        if (not y_is_positive) and x_from_camera_more_than_z_from_camera and x_from_camera_more_than_y_from_camera:
            write_to_image_file(back_projection, camera_x, camera_z, neg_y)
    return front_projection,right_projection,left_projection,back_projection
    
def find_and_match():
    image_front = cv2.imread("data/image/front.jpg", cv2.IMREAD_COLOR)
    image_back = cv2.imread("data/image/back.jpg", cv2.IMREAD_COLOR)
    image_left = cv2.imread("data/image/left.jpg", cv2.IMREAD_COLOR)
    image_right = cv2.imread("data/image/right.jpg", cv2.IMREAD_COLOR)

    front_projection = cv2.imread("front_projection.png")
    back_projection = cv2.imread("back_projection.png")
    left_projection = cv2.imread("left_projection.png")
    right_projection = cv2.imread("right_projection.png")
    # Initiate ORB detector
    orb = cv2.ORB_create()

    front_image_keypoints, front_image_descriptors = orb.detectAndCompute(image_front, None)
    left_image_keypoints, left_image_descriptors = orb.detectAndCompute(image_left, None)
    right_image_keypoints, right_image_descriptors = orb.detectAndCompute(image_right, None)
    back_image_keypoints, back_image_descriptors = orb.detectAndCompute(image_back, None)
    
    front_projection_keypoints, front_projection_descriptors = orb.detectAndCompute(front_projection, None)
    
    left_projection_keypoints, left_projection_descriptors = orb.detectAndCompute(left_projection, None)
    right_projection_keypoints, right_projection_descriptors = orb.detectAndCompute(right_projection, None)
    back_projection_keypoints, back_projection_descriptors = orb.detectAndCompute(back_projection, None)

    # Initiate Brute Force matcher
    bf_matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    front_matches = bf_matcher.match(front_image_descriptors, front_projection_descriptors)
    left_matches = bf_matcher.match(left_image_descriptors, left_projection_descriptors)
    right_matches = bf_matcher.match(right_image_descriptors, right_projection_descriptors)
    back_matches = bf_matcher.match(back_image_descriptors, back_projection_descriptors)

    front_matches = sorted(front_matches, key=lambda val: val.distance)
    left_matches = sorted(left_matches, key=lambda val: val.distance)
    right_matches = sorted(right_matches, key=lambda val: val.distance)
    back_matches = sorted(back_matches, key=lambda val: val.distance)

    keypoints = [front_image_keypoints, left_image_keypoints, right_image_keypoints, back_image_keypoints,
        front_projection_keypoints, left_projection_keypoints, right_projection_keypoints, back_projection_keypoints]
    descriptors = [front_image_descriptors, left_image_descriptors, right_image_descriptors, back_image_descriptors,
        front_projection_descriptors, left_projection_descriptors, right_projection_descriptors, back_projection_descriptors]
    matches = [front_matches, left_matches, right_matches, back_matches]


#Added Extra Part For checking
##    sample=cv2.drawMatches(image_front,front_image_keypoints,front_projection,front_projection_keypoints,matches[:20],flags=2,**self.draw)
##    plt.imshow(img3, 'gray'),plt.show()
    return keypoints, descriptors, matches



def calculate_error_angle(image, img_keys, prj_keys, matches):
    """
    Calculates the angle of error between a perspective image
    and the image created from a projected point cloud
    """
    angles = []
    for match in matches:
        endpoint_1 = tuple(np.round(img_keys[match.trainIdx].pt).astype(int))
        endpoint_2 = tuple(np.round(prj_keys[match.queryIdx].pt).astype(int) + np.array([image.shape[1], 0]))
        angles.append(math.atan((float)(endpoint_2[1] - endpoint_1[1]) / (endpoint_1[0] - endpoint_2[0])) * (180 / math.pi))
    
    return sum(angles)/len(angles)

def get_error_angles(keypoints, matches):
    """ Calls 'calculate_error_angle' for each perspective/projection pair """
    error_angles = []
    images = load_images()
    front_angle = calculate_error_angle(images[0], keypoints[0], keypoints[4], matches[0])
    error_angles.append(front_angle)
    left_angle = calculate_error_angle(images[1], keypoints[1], keypoints[5], matches[1])
    error_angles.append(left_angle)
    right_angle = calculate_error_angle(images[2], keypoints[2], keypoints[6], matches[2])
    error_angles.append(right_angle)
    back_angle = calculate_error_angle(images[3], keypoints[3], keypoints[7], matches[3])
    error_angles.append(back_angle)

    return error_angles

def output_errors(error_angles):
    """ Prints Angle Errors between perspective images and projection images """
    print("Front projection to perspective angle error: ", error_angles[0])
    print("Left projection to perspective angle error: ", error_angles[1])
    print("Right projection to perspective angle error: ", error_angles[2])
    print("Back projection to perspective angle error: ", error_angles[3])
    return
def main():
    read_image_files()
    map_points()
    keypoints, descriptors, matches = find_and_match
    
    return
    
def main():

    point_cloud1=read_image_files()
##    print(camera_config1)
##    print(point_cloud1[0])
    front_projection,right_projection,left_projection,back_projection=map_points(point_cloud1)
    cv2.imwrite('front_projection.png', front_projection)
    cv2.imwrite('back_projection.png', back_projection)
    cv2.imwrite('left_projection.png', left_projection)
    cv2.imwrite('right_projection.png', right_projection)
    keypoints, descriptors, matches = find_and_match()
    
    print(keypoints)
    # Matrix transformation
    # Create images from point cloud
    # Detect and match keypoints
    # comparison()

if __name__ == "__main__":
    main()
